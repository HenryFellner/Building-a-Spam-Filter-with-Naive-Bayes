{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes\n",
    "\n",
    "This project will seek to create a system to try and automatically detect SMS messages categorized as \"Spam\". We effectively need to teach the computer how to do so using a set of over five thousand SMS messages that have been classified by humans as spam already.\n",
    "\n",
    "The dataset from The UCI Machine Learning Repository can be found [here](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). We begin by reading in the dataset as a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n",
      "  Label                                                SMS\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "ham     86.593683\n",
      "spam    13.406317\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "SMS_spam = pd.read_csv('SMSSpamCollection', sep='\\t', header = None, names = ['Label', 'SMS'])\n",
    "print(SMS_spam.shape)\n",
    "print(SMS_spam.head())\n",
    "print(SMS_spam['Label'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the general structure of the dataframe. It is relatively simple, with only two columns, one indicating whether or not it is spam, and another containing the string of the text. \n",
    "\n",
    "There's a heathy 5,572 rows. Around 13.4% of the rows are spam, while the remaining 86.59% are non-spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Set and Test Set\n",
    "\n",
    "We need to see if our model is effective, but the only data we have to test it against human classification is the data we are going to use to create/train it. So we will take 20% of the data out randomly, and use it to test the model after the fact (which will be trained with the remaining 80%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80% of the dataset is 4457.6 rows.\n"
     ]
    }
   ],
   "source": [
    "SMS_full_sample = SMS_spam.sample(frac=1, random_state=1) \n",
    "#random-order of dataset\n",
    "\n",
    "print('80% of the dataset is {} rows.'.format(len(SMS_full_sample)*0.8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomized our dataset, and found 80% to be 4457.6, rounded to 4458. So the training set will take the first 4,458 rows of the randomized set (As it is randomized already, taking the first 80% of rows is not a biased selection). The remaining 1,114 rows will be the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     86.54105\n",
      "spam    13.45895\n",
      "Name: Label, dtype: float64\n",
      "ham     86.804309\n",
      "spam    13.195691\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_set = SMS_full_sample[:4458].reset_index()\n",
    "test_set = SMS_full_sample[4458:].reset_index()\n",
    "#reset_index clears the randomly unordered indexes from our new sets.\n",
    "\n",
    "print(train_set['Label'].value_counts(normalize=True)*100)\n",
    "print(test_set['Label'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the value counts for both the training set and test set are about the same, still 86 or 87% versus 13%. This resembes the full dataset, so we can proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning the Training Set\n",
    "\n",
    "We first need to clean and standardize the format of the SMS texts so we can easily interpret them in our analysis. We start by removing the punctuation and covnerting all words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index Label                                                SMS\n",
      "0   1078   ham                       yep  by the pretty sculpture\n",
      "1   4028   ham      yes  princess  are you going to make me moan \n",
      "2    958   ham                         welp apparently he retired\n",
      "3   4642   ham                                            havent \n",
      "4   4674   ham  i forgot 2 ask ü all smth   there s a card on ...\n"
     ]
    }
   ],
   "source": [
    "train_set['SMS'] = train_set['SMS'].str.replace('\\W', ' ').str.lower()\n",
    "\n",
    "print(train_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see inthe header there is a distinct lack of punctuation.\n",
    "\n",
    "Next we need to create a vocabulary of all words found within the SMS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set['SMS'] = train_set['SMS'].str.split()\n",
    "# Try not to run this more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = []\n",
    "for text in train_set['SMS']:\n",
    "    for word in text:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = set(vocabulary)\n",
    "#Turns the list of words into a set, removing duplicates.\n",
    "\n",
    "vocabulary = list(vocabulary)\n",
    "#Turns the set of words back into a list, the desired format but still no duplicates.\n",
    "\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are 7,783 unique words within our training set. We want to have lists this long so each value in the list acts as a word count for that unique word in an SMS message.\n",
    "\n",
    "We create a blank version of this by making a dictionary, wher each word is the key and the values are 7,783 zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(train_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, text in enumerate(train_set['SMS']):\n",
    "    for word in text:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "\n",
    "word_counts_df = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index Label                                                SMS  0  00  000  \\\n",
      "0   1078   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
      "1   4028   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
      "2    958   ham                    [welp, apparently, he, retired]  0   0    0   \n",
      "3   4642   ham                                           [havent]  0   0    0   \n",
      "4   4674   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
      "\n",
      "   000pes  008704050406  0089  01223585334 ...  zindgi  zoe  zogtorius  zouk  \\\n",
      "0       0             0     0            0 ...       0    0          0     0   \n",
      "1       0             0     0            0 ...       0    0          0     0   \n",
      "2       0             0     0            0 ...       0    0          0     0   \n",
      "3       0             0     0            0 ...       0    0          0     0   \n",
      "4       0             0     0            0 ...       0    0          0     0   \n",
      "\n",
      "   zyada  é  ú1  ü  〨ud  鈥  \n",
      "0      0  0   0  0    0  0  \n",
      "1      0  0   0  0    0  0  \n",
      "2      0  0   0  0    0  0  \n",
      "3      0  0   0  0    0  0  \n",
      "4      0  0   0  2    0  0  \n",
      "\n",
      "[5 rows x 7786 columns]\n"
     ]
    }
   ],
   "source": [
    "train_clean = pd.concat([train_set, word_counts_df], axis=1)\n",
    "print(train_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each row consists of the label, the words within it, and a word count of every single unique word in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Constant Variables\n",
    "\n",
    "Some of the values we need to create our model vary from row to row, but some of them, such as the overall probability of an email being spam vs non-spam is constant. We can calculate the constants to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13458950201884254\n",
      "0.8654104979811574\n",
      "7783\n",
      "15190\n",
      "57237\n"
     ]
    }
   ],
   "source": [
    "ct_spam = train_clean[train_clean['Label'] == 'spam']['Label'].count()\n",
    "ct_ham = train_clean[train_clean['Label'] == 'ham']['Label'].count()\n",
    "#count the number of rows that are spam and ham\n",
    "\n",
    "p_spam = ct_spam/len(train_clean)\n",
    "p_ham = ct_ham/len(train_clean)\n",
    "# divide by total for probabilities\n",
    "\n",
    "n_vocab = len(vocabulary)\n",
    " \n",
    "n_words_per_spam_message = train_clean[train_clean['Label'] == 'spam']['SMS'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "n_words_per_ham_message = train_clean[train_clean['Label'] == 'ham']['SMS'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "print(p_spam)\n",
    "print(p_ham)\n",
    "print(n_vocab)\n",
    "print(n_spam)\n",
    "print(n_ham)\n",
    "\n",
    "alpha = 1\n",
    "# For the Laplace smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Calculating Parameters\n",
    "\n",
    "For each of the 7,783 words in our vocabulary, we need to calcuate the probability: P(w|Spam) and P(w|Ham), where w is a variable for the word. \n",
    "\n",
    "We can create two dictionaries, one for 'Spam' and one for 'Ham' that will hold all of these parameters. We initialize these as blank, with each key being a unique vocab word and each value being zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_spam = train_clean[train_clean['Label'] == 'spam']\n",
    "train_ham = train_clean[train_clean['Label'] == 'ham']\n",
    "\n",
    "parameters_spam ={word: 0 for word in vocabulary}\n",
    "parameters_ham ={word: 0 for word in vocabulary}\n",
    "#Initialized parameters, all zero values.\n",
    "\n",
    "for word in vocabulary:\n",
    "    n_wi_spam = train_spam[word].sum()\n",
    "    n_wi_ham = train_ham[word].sum()\n",
    "    \n",
    "    parameters_spam[word] = (n_wi_spam + alpha)/(n_spam + (alpha * n_vocab))\n",
    "    parameters_ham[word] = (n_wi_ham + alpha)/(n_ham + (alpha * n_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then looped through each word in the dictionary and calculated its parameter for both 'Spam' and 'Ham' (non-spam)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying New Messages\n",
    "\n",
    "Now that we have our parameters set up, we need a function to take in a string input and output whether it is more likely 'spam' or 'ham', based on our current probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        \n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "            \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a function, classify(), that inputs a string and outputs whether or not it is likely Spam or non-Spam. Let's test it with two new strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n",
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')\n",
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct! For these two examples, the first seems to have been properly identified as spam and the second as non-spam. We can now apply this to our test set to see our success rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Accuracy on Test Set\n",
    "\n",
    "We need to revise our classify function to returning the results rather than printing them, so we can calculate total statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        \n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our function we can use apply() to put it over the entire test set in a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2131</td>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3418</td>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3424</td>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1538</td>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5393</td>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Label                                                SMS predicted\n",
       "0   2131   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   3418   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2   3424  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   1538   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   5393   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now tht we have the new column we just have to count for the dataframe all the times in which our predicted value, spam or ham, matches the human-determined label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n",
      "98.74326750448833\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test_set)\n",
    "\n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "print(correct)\n",
    "print(100*correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find our program to be 98.74% effective, correctly identifying all but 14 of the 1,114 test set SMS messages. This is a great success rate, and much higher than expected!\n",
    "\n",
    "Let's quickly take a look at the 14 messages incorrectly identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>3460</td>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1940</td>\n",
       "      <td>spam</td>\n",
       "      <td>More people are dogging in your area now. Call...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>3890</td>\n",
       "      <td>ham</td>\n",
       "      <td>Unlimited texts. Limited minutes.</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>991</td>\n",
       "      <td>ham</td>\n",
       "      <td>26th OF JULY</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>4862</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>2370</td>\n",
       "      <td>ham</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>326</td>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>5046</td>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>3864</td>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>4676</td>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>1638</td>\n",
       "      <td>spam</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>3302</td>\n",
       "      <td>spam</td>\n",
       "      <td>RCT' THNQ Adrian for U text. Rgds Vatian</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>3742</td>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>869</td>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index Label                                                SMS  \\\n",
       "114   3460  spam  Not heard from U4 a while. Call me now am here...   \n",
       "135   1940  spam  More people are dogging in your area now. Call...   \n",
       "152   3890   ham                  Unlimited texts. Limited minutes.   \n",
       "159    991   ham                                       26th OF JULY   \n",
       "284   4862   ham                             Nokia phone is lovly..   \n",
       "293   2370   ham  A Boy loved a gal. He propsd bt she didnt mind...   \n",
       "302    326   ham                   No calls..messages..missed calls   \n",
       "319   5046   ham  We have sent JD for Customer Service cum Accou...   \n",
       "504   3864  spam  Oh my god! I've found your number again! I'm s...   \n",
       "546   4676  spam  Hi babe its Chloe, how r u? I was smashed on s...   \n",
       "741   1638  spam  0A$NETWORKS allow companies to bill for SMS, s...   \n",
       "876   3302  spam           RCT' THNQ Adrian for U text. Rgds Vatian   \n",
       "885   3742  spam                                      2/2 146tf150p   \n",
       "953    869  spam  Hello. We need some posh birds and chaps to us...   \n",
       "\n",
       "                      predicted  \n",
       "114                         ham  \n",
       "135                         ham  \n",
       "152                        spam  \n",
       "159                        spam  \n",
       "284                        spam  \n",
       "293  needs human classification  \n",
       "302                        spam  \n",
       "319                        spam  \n",
       "504                         ham  \n",
       "546                         ham  \n",
       "741                         ham  \n",
       "876                         ham  \n",
       "885                         ham  \n",
       "953                         ham  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong = test_set[test_set['Label'] != test_set['predicted']]\n",
    "wrong.head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "By looking at the 14 events our system incorrectly described as spam or non-spam, we can see some possible reasons why.\n",
    "\n",
    "* It sometimes identifies ham messages where phones and calls are being described as spam, likely because this subject matter is common in spam.\n",
    "* Messages with spelling errors also seem occasionally misidentified as spam when they are non-spam.\n",
    "* Spam messages that try to come off as a friend speaking (i.e.: 'Oh my god! I've found your number again!...') and seem more human slide past the filter.\n",
    "\n",
    "This project was a great look at how probabilities can be used in a practical way, as simple arithmatic has led to a wildly successful text filter being created. Some of the principles in this project are keys in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
